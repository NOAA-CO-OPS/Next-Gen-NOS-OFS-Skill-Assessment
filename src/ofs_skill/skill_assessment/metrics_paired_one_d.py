"""
Calculate skill metrics for paired one-dimensional time series.

This module takes pandas dataframes generated by get_skill.py and calculates
skill assessment metrics. The output is a list with the result for each metric.
"""

import math
import os
import warnings
from logging import Logger
from typing import Any, Union

import numpy as np
import pandas as pd
from scipy import stats
from scipy.stats import ConstantInputWarning
from sklearn.metrics import root_mean_squared_error

warnings.simplefilter('ignore', ConstantInputWarning)


def get_error_range(
    name_var: str,
    prop: Any,
    logger: Logger,
) -> tuple[float, float]:
    """
    Get error range thresholds for a given variable.

    Reads error ranges from configuration file or uses default values if file
    doesn't exist. Error ranges define acceptable model performance thresholds.

    Parameters
    ----------
    name_var : str
        Variable name ('wl', 'temp', 'salt', or 'cu')
    prop : Any
        Properties object containing path attribute
    logger : Logger
        Logger instance for logging messages

    Returns
    -------
    Tuple[float, float]
        Tuple of (X1, X2) where:
        - X1: Primary error range threshold
        - X2: Secondary error range threshold
    """
    filename = 'error_ranges.csv'
    filepath = os.path.join(prop.path, 'conf', filename)
    if os.path.isfile(filepath) is True:
        # Dataframe of error range file!
        df = pd.read_csv(filepath)
        subs = df[df['name_var'] == name_var]

    else:
        # Make file using default values
        errordata = [['salt', 3.5, 0.5], ['temp', 3, 0.5], ['wl', 0.15, 0.5],
                     ['cu', 0.26, 0.5]]
        df = pd.DataFrame(errordata, columns=['name_var', 'X1', 'X2'])
        subs = df[df['name_var'] == name_var]
        df.to_csv(filepath, index=False)

    # Get error ranges for variable
    X1 = pd.to_numeric(subs['X1']).values[0]
    X2 = pd.to_numeric(subs['X2']).values[0]

    return X1, X2


def skill_scalar(
    df_paired: pd.DataFrame,
    name_var: str,
    prop: Any,
    logger: Logger,
) -> list[Union[float, str]]:
    """
    Calculate skill metrics for scalar variables.

    Computes skill assessment metrics including RMSE, correlation coefficient,
    bias, central frequency, and outlier frequencies for scalar variables
    (water level, temperature, salinity).

    Parameters
    ----------
    df_paired : pd.DataFrame
        Paired observation and model data with columns ['OBS', 'OFS', 'BIAS']
    name_var : str
        Variable name ('wl', 'temp', or 'salt')
    prop : Any
        Properties object containing configuration parameters
    logger : Logger
        Logger instance for logging messages

    Returns
    -------
    List[Union[float, str]]
        List of skill metrics:
        [rmse, r_value, bias, bias_perc, np.nan, cf, cfpf, pof, pofpf,
         nof, nofpf, stdev, X1]
        Where:
        - rmse: Root mean squared error
        - r_value: Pearson correlation coefficient
        - bias: Mean bias
        - bias_perc: Mean bias as percentage of mean observation
        - cf: Central frequency (percentage within error threshold)
        - cfpf: Central frequency pass/fail ('pass' if >= 90%)
        - pof: Positive outlier frequency
        - pofpf: Positive outlier frequency pass/fail
        - nof: Negative outlier frequency
        - nofpf: Negative outlier frequency pass/fail
        - stdev: Standard deviation of bias
        - X1: Error threshold

    Notes
    -----
    Some stations have constant values for the entire period. By definition,
    correlation cannot be calculated between observations and model if one
    of the timeseries is constant, which will trigger a warning.
    """
    datathreshold = 5

    # Get target error range
    X1, X2 = get_error_range(name_var, prop, logger)

    df_paired = df_paired.dropna(subset=['OBS', 'OFS'])
    # Update obs and ofs after handling NaN
    obs = df_paired['OBS']
    ofs = df_paired['OFS']
    df_bias = df_paired['BIAS']

    if np.nansum(~np.isnan(obs)) >= datathreshold:
        # RMSE -- fixed 8/13/24
        rmse = root_mean_squared_error(obs, ofs)
        rmse = np.around(rmse, decimals=2)

        # Pearson's R
        r_value = stats.pearsonr(obs, ofs)[0]
        if math.isnan(r_value):
            logger.warning(
                '%s -- The correlation coefficient could not be calculated (i.e. R=NaN)', name_var)
        r_value = np.around(r_value, decimals=2)

        # Mean bias & bias percent
        bias = df_bias.mean()  # Series mean from fortran SA
        bias = np.around(bias, decimals=2)
        bias_perc = 100 * (bias / obs.mean())
        bias_perc = np.around(bias_perc, decimals=2)

        # Central frequency
        # Not using X2 right now, only X1
        npbias = np.array(df_bias)
        cf = ((((-X1 < npbias) & (npbias < X1)).sum())/len(npbias))*100
        cf = np.around(cf, decimals=2)
        # Pass or fail?
        if cf >= 90:
            cfpf = 'pass'
        else:
            cfpf = 'fail'

        # Positive/negative outlier frequency
        pof = (((2*X1 < npbias).sum())/len(npbias))*100
        pof = np.around(pof, decimals=2)
        if pof <= 1:
            pofpf = 'pass'
        else:
            pofpf = 'fail'
        nof = (((npbias < -2*X1).sum())/len(npbias))*100
        nof = np.around(nof, decimals=2)
        if nof <= 1:
            nofpf = 'pass'
        else:
            nofpf = 'fail'

        # Standard deviation or error/bias
        stdev = np.std(npbias)
        stdev = np.around(stdev, decimals=2)

    else:
        nodatatext = '<' + str(datathreshold) + ' data points'
        rmse = nodatatext
        r_value = nodatatext
        bias = nodatatext
        bias_perc = nodatatext
        cf = nodatatext
        cfpf = nodatatext
        pof = nodatatext
        pofpf = nodatatext
        nof = nodatatext
        nofpf = nodatatext
        stdev = nodatatext

    # Return stats
    return [rmse,
            r_value,
            bias,
            bias_perc,
            np.nan,
            cf,
            cfpf,
            pof,
            pofpf,
            nof,
            nofpf,
            stdev,
            X1]


def skill_vector(
    df_paired: pd.DataFrame,
    name_var: str,
    prop: Any,
    logger: Logger,
) -> list[Union[float, str]]:
    """
    Calculate skill metrics for vector variables.

    Computes skill assessment metrics including RMSE, correlation coefficient,
    speed bias, direction bias, central frequency, and outlier frequencies for
    vector variables (currents).

    Parameters
    ----------
    df_paired : pd.DataFrame
        Paired observation and model data with columns ['OBS', 'OFS',
        'SPD_BIAS', 'DIR_BIAS']
    name_var : str
        Variable name ('cu' for currents)
    prop : Any
        Properties object containing configuration parameters
    logger : Logger
        Logger instance for logging messages

    Returns
    -------
    List[Union[float, str]]
        List of skill metrics:
        [rmse, r_value, bias, bias_perc, bias_dir, cf, cfpf, pof, pofpf,
         nof, nofpf, stdev, X1]
        Where:
        - rmse: Root mean squared error of speed
        - r_value: Pearson correlation coefficient of speed
        - bias: Mean speed bias
        - bias_perc: Mean speed bias as percentage
        - bias_dir: Mean direction bias
        - cf: Central frequency (percentage within error threshold)
        - cfpf: Central frequency pass/fail ('pass' if >= 90%)
        - pof: Positive outlier frequency
        - pofpf: Positive outlier frequency pass/fail
        - nof: Negative outlier frequency
        - nofpf: Negative outlier frequency pass/fail
        - stdev: Standard deviation of speed bias
        - X1: Error threshold
    """
    datathreshold = 5

    # Get target error range
    X1, X2 = get_error_range(name_var, prop, logger)

    df_paired = df_paired.dropna(subset=['OBS', 'OFS'])
    # Update obs and ofs after handling NaN
    obs = df_paired['OBS']
    ofs = df_paired['OFS']
    spd_bias = df_paired['SPD_BIAS']
    dir_bias = df_paired['DIR_BIAS']
    if np.nansum(~np.isnan(obs)) >= datathreshold:
        # RMSE -- fixed 8/13/24
        rmse = root_mean_squared_error(obs, ofs)
        rmse = np.around(rmse, decimals=2)

        # Pearson's R
        r_value = stats.pearsonr(obs, ofs)[0]
        if math.isnan(r_value):
            logger.warning(
                '%s -- The correlation coefficient could not be calculated (i.e. R=NaN)',
                name_var)
        r_value = np.around(r_value, decimals=2)

        # Mean bias & bias percent
        bias = spd_bias.mean()
        bias_perc = 100 * (bias / obs.mean())
        bias = np.around(bias, decimals=2)
        bias_perc = np.around(bias_perc, decimals=2)
        bias_dir = dir_bias.mean()
        bias_dir = np.around(bias_dir, decimals=2)

        # Central frequency
        # Not using X2 right now, only X1
        npbias = np.array(spd_bias)
        cf = ((((-X1 <= npbias) & (npbias <= X1)).sum())/len(npbias))*100
        cf = np.around(cf, decimals=2)
        # Pass or fail?
        if cf >= 90:
            cfpf = 'pass'
        else:
            cfpf = 'fail'

        # Positive/negative outlier frequency
        pof = (((2*X1 <= npbias).sum())/len(npbias))*100
        pof = np.around(pof, decimals=2)
        if pof <= 1:
            pofpf = 'pass'
        else:
            pofpf = 'fail'
        nof = (((npbias <= -2*X1).sum())/len(npbias))*100
        nof = np.around(nof, decimals=2)
        if nof <= 1:
            nofpf = 'pass'
        else:
            nofpf = 'fail'

        # Standard deviation or error/bias
        stdev = np.std(npbias)
        stdev = np.around(stdev, decimals=2)
    else:
        nodatatext = '<' + str(datathreshold) + ' data points'
        rmse = nodatatext
        r_value = nodatatext
        bias = nodatatext
        bias_perc = nodatatext
        bias_dir = nodatatext
        cf = nodatatext
        cfpf = nodatatext
        pof = nodatatext
        pofpf = nodatatext
        nof = nodatatext
        nofpf = nodatatext
        stdev = nodatatext

    return [rmse,
            r_value,
            bias,
            bias_perc,
            bias_dir,
            cf,
            cfpf,
            pof,
            pofpf,
            nof,
            nofpf,
            stdev,
            X1]
